{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9Os2D8bjZtU",
        "outputId": "f061707d-8b77-4b19-f997-f6517992e495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fGjPdnhSjWZ3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8ltpQAIAjWZ5"
      },
      "outputs": [],
      "source": [
        "train_path = 'D:/WORK/Tomato Disease Prediction/5. Project Executable Files/Dataset/train'\n",
        "val_path = 'D:/WORK/Tomato Disease Prediction/5. Project Executable Files/Dataset/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wHzzQCCjWZ5",
        "outputId": "0dcd23e1-e3cf-4044-8ea2-a2bbf6256f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 10 classes.\n",
            "Found 1000 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Apply ImageDataGenerator functionality to Trainset and Test set\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=80,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=80,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sPP-entjWZ6",
        "outputId": "190e9a9c-cad5-4a87-a326-a61020ed3d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "# Adding Dense Layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# The final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Configure the Learning Process\n",
        "for layers in base_model.layers[:140]:\n",
        "    layers.trainable=False\n",
        "for layers in base_model.layers[140:]:\n",
        "    layers.trainable=True\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics='accuracy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZreOyN4jWZ6",
        "outputId": "936381fc-cd12-4d51-cbaf-fa6bd5513bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "125/125 [==============================] - 2803s 22s/step - loss: 0.9972 - accuracy: 0.7046 - val_loss: 0.6202 - val_accuracy: 0.8020\n",
            "Epoch 2/15\n",
            "125/125 [==============================] - 280s 2s/step - loss: 0.2472 - accuracy: 0.9249 - val_loss: 0.2086 - val_accuracy: 0.9270\n",
            "Epoch 3/15\n",
            "125/125 [==============================] - 281s 2s/step - loss: 0.1346 - accuracy: 0.9581 - val_loss: 0.1439 - val_accuracy: 0.9510\n",
            "Epoch 4/15\n",
            "125/125 [==============================] - 280s 2s/step - loss: 0.0971 - accuracy: 0.9691 - val_loss: 0.1590 - val_accuracy: 0.9430\n",
            "Epoch 5/15\n",
            "125/125 [==============================] - 281s 2s/step - loss: 0.0710 - accuracy: 0.9772 - val_loss: 0.1339 - val_accuracy: 0.9570\n",
            "Epoch 6/15\n",
            "125/125 [==============================] - 280s 2s/step - loss: 0.0550 - accuracy: 0.9828 - val_loss: 0.0997 - val_accuracy: 0.9690\n",
            "Epoch 7/15\n",
            "125/125 [==============================] - 282s 2s/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.0921 - val_accuracy: 0.9780\n",
            "Epoch 8/15\n",
            "125/125 [==============================] - 284s 2s/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.0845 - val_accuracy: 0.9760\n",
            "Epoch 9/15\n",
            "125/125 [==============================] - 280s 2s/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.0707 - val_accuracy: 0.9800\n",
            "Epoch 10/15\n",
            "125/125 [==============================] - 280s 2s/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.0753 - val_accuracy: 0.9770\n",
            "Epoch 11/15\n",
            "125/125 [==============================] - 280s 2s/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.0862 - val_accuracy: 0.9680\n",
            "Epoch 12/15\n",
            "125/125 [==============================] - 280s 2s/step - loss: 0.0201 - accuracy: 0.9946 - val_loss: 0.0720 - val_accuracy: 0.9750\n",
            "Epoch 13/15\n",
            "125/125 [==============================] - 280s 2s/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 0.0713 - val_accuracy: 0.9750\n",
            "Epoch 14/15\n",
            "125/125 [==============================] - 279s 2s/step - loss: 0.0215 - accuracy: 0.9929 - val_loss: 0.0619 - val_accuracy: 0.9800\n",
            "Epoch 15/15\n",
            "125/125 [==============================] - 281s 2s/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.0656 - val_accuracy: 0.9790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=15\n",
        ")\n",
        "\n",
        "# Save the Model\n",
        "model.save('tomato_disease_detector.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YzIRS6gfm1W_"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/tomato_disease_detector.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qTtpoyFpjWZ8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "The disease detected is: Tomato___Spider_mites Two-spotted_spider_mite\n"
          ]
        }
      ],
      "source": [
        "# Import additional libraries for handling image input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('tomato_disease_detector.h5')\n",
        "\n",
        "# Define a function to preprocess the input image and make a prediction\n",
        "def predict_disease(img_path):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "    disease_name = class_indices[predicted_class]\n",
        "\n",
        "    return disease_name\n",
        "\n",
        "# Test the function\n",
        "img_path = 'im1.JPG'  # Replace with the path to your test image\n",
        "disease_name = predict_disease(img_path)\n",
        "print(f\"The disease detected is: {disease_name}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
